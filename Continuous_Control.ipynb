{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca57162",
   "metadata": {},
   "source": [
    "# Continuous Control Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a75b37",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5de83a",
   "metadata": {},
   "source": [
    "This section prepares the environment by updating system paths, installing dependencies (e.g., NumPy, PyTorch), and importing libraries for numerical operations, randomness, plotting, and Unity environment interaction. It also selects the computation device (GPU or CPU) for efficient processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab98089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the PATH env var. \n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/home/student/.local/bin\"\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/opt/conda/lib/python3.10/site-packages\"\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5553107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==1.26.3\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip freeze | grep numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3286e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912db67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/student/.local/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/student/.local/lib/python3.11/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/student/.local/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/student/.local/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/student/.local/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/student/.local/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/student/.local/lib/python3.11/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/student/.local/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/student/.local/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/student/.local/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/student/.local/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/student/.local/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/student/.local/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/student/.local/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/student/.local/lib/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/student/.local/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/student/.local/lib/python3.11/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/student/.local/lib/python3.11/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/student/.local/lib/python3.11/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (68.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/student/.local/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3976ed65",
   "metadata": {},
   "source": [
    "### Restart the Kernel at this step on the first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e2058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import deque, namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from unityagents import UnityEnvironment\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d41c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define computation device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f33aecd",
   "metadata": {},
   "source": [
    "## Section 2: Initialize environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d638e0e7",
   "metadata": {},
   "source": [
    "Here, the Unity Reacher environment is loaded, and critical parameters—number of agents, action size (4), and state size (33)—are extracted and displayed. This confirms the environment is ready for multi-agent training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b7c5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found path: /data/Reacher_Linux_NoVis/Reacher.x86_64\n",
      "Mono path[0] = '/data/Reacher_Linux_NoVis/Reacher_Data/Managed'\n",
      "Mono config path = '/data/Reacher_Linux_NoVis/Reacher_Data/MonoBleedingEdge/etc'\n",
      "Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "Unable to preload the following plugins:\n",
      "\tlibgrpc_csharp_ext.x86.so\n",
      "Logging to /home/student/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "State size per agent: 33\n"
     ]
    }
   ],
   "source": [
    "# Initialize environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "num_agents = len(env_info.agents)\n",
    "action_size = brain.vector_action_space_size\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print(f'Number of agents: {num_agents}')\n",
    "print(f'Size of each action: {action_size}')\n",
    "print(f'State size per agent: {state_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077a8e7",
   "metadata": {},
   "source": [
    "## Section 3: State and Action Space Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232ac15",
   "metadata": {},
   "source": [
    "In the Reacher environment, the objective is for a double-jointed robotic arm to move its end-effector to follow a moving target as closely as possible. The environment features a continuous state space and a continuous action space, which define how the agent observes its surroundings and takes actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e7b6be",
   "metadata": {},
   "source": [
    "#### State Space (Observations)\n",
    "The state space is a 33-dimensional continuous vector that captures the current state of the robotic arm and its relationship to the target. The components of this vector include:\n",
    "- Joint Positions: Spatial coordinates of the arm's joints.\n",
    "\n",
    "- Joint Rotations: Orientation of the joints.\n",
    "\n",
    "- Joint Velocities: Speed of the joints' movements.\n",
    "\n",
    "- Angular Velocities: Rate of rotation of the joints.\n",
    "\n",
    "- Target Position: Coordinates of the moving target the arm must track.\n",
    "\n",
    "This 33-element observation vector is updated at each time step, providing the agent with a detailed snapshot of the arm's dynamics and the target's location.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c7c34",
   "metadata": {},
   "source": [
    "#### Action Space\n",
    "The action space is continuous and consists of a 4-dimensional vector, where each value ranges from -1 to 1. These values represent the torques applied to the arm's joints:\n",
    "- Action 0: Torque for the first joint.\n",
    "\n",
    "- Action 1: Torque for the second joint.\n",
    "\n",
    "- Action 2: Torque for the third joint.\n",
    "\n",
    "- Action 3: Torque for the fourth joint.\n",
    "\n",
    "By adjusting these torques, the agent controls the arm's movement to align the end-effector with the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa06f586",
   "metadata": {},
   "source": [
    "## Section 4: Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad119fe0",
   "metadata": {},
   "source": [
    "- hidden_init initializes neural network weights for stability.\n",
    "- cleanup_zombie_processes terminates lingering Reacher processes to free system resources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422c0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_init(layer):\n",
    "    \"\"\"Initialize hidden layer weights with uniform distribution.\"\"\"\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19dc67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_zombie_processes():\n",
    "    \"\"\"Terminate parent processes of zombie Reacher instances.\"\"\"\n",
    "    for proc in psutil.process_iter(['pid', 'ppid', 'name', 'status']):\n",
    "        if 'Reacher' in proc.info['name'] and proc.info['status'] == psutil.STATUS_ZOMBIE:\n",
    "            print(f\"Zombie process detected: {proc.info}\")\n",
    "            parent = psutil.Process(proc.info['ppid'])\n",
    "            print(f\"Terminating parent process: {parent}\")\n",
    "            parent.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48471fa",
   "metadata": {},
   "source": [
    "## Section 5: Actor and Critics Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b396cd",
   "metadata": {},
   "source": [
    "The Actor network maps states to actions using ReLU and tanh activations, while the Critic network estimates Q-values for state-action pairs with leaky ReLU activations. Both use feedforward architectures with weight initialization for training stability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18eb888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor network mapping states to actions.\"\"\"\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=400, fc2_units=300):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state_size (int): State dimension\n",
    "            action_size (int): Action dimension\n",
    "            seed (int): Random seed for reproducibility\n",
    "            fc1_units (int): Units in first hidden layer\n",
    "            fc2_units (int): Units in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.bn1 = nn.BatchNorm1d(fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Set initial weights using uniform distribution.\"\"\"\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Map state to action using ReLU and tanh activations.\"\"\"\n",
    "        x = F.relu(self.bn1(self.fc1(state)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a10c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic network estimating Q-values for state-action pairs.\"\"\"\n",
    "    def __init__(self, state_size, action_size, seed, fcs1_units=400, fc2_units=300):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state_size (int): State dimension\n",
    "            action_size (int): Action dimension\n",
    "            seed (int): Random seed for reproducibility\n",
    "            fcs1_units (int): Units in first hidden layer\n",
    "            fc2_units (int): Units in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fcs1_units)\n",
    "        self.bn1 = nn.BatchNorm1d(fcs1_units)\n",
    "        self.fc2 = nn.Linear(fcs1_units + action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 1)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Set initial weights using uniform distribution.\"\"\"\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Map (state, action) to Q-value using leaky ReLU activations.\"\"\"\n",
    "        xs = F.leaky_relu(self.bn1(self.fcs1(state)))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b2fbe",
   "metadata": {},
   "source": [
    "## Section 6: Replay Buffer and Ornstein-Uhlenbeck Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d459b5f",
   "metadata": {},
   "source": [
    "The Replay Buffer stores experience tuples (state, action, reward, next state, done) for off-policy learning, sampling random batches. The OUNoise class adds exploration noise to actions using the Ornstein-Uhlenbeck process, aiding policy discovery.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "937ca1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Buffer storing experience tuples for off-policy learning.\"\"\"\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            action_size (int): Action dimension\n",
    "            buffer_size (int): Maximum buffer capacity\n",
    "            batch_size (int): Size of sampled batches\n",
    "            seed (int): Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Store a new experience tuple.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Sample a random batch of experiences.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences]).astype(np.uint8)).float().to(device)\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ea196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck noise for action exploration.\"\"\"\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            size (int): Action dimension\n",
    "            seed (int): Random seed for reproducibility\n",
    "            mu (float): Mean of noise\n",
    "            theta (float): Drift coefficient\n",
    "            sigma (float): Volatility coefficient\n",
    "        \"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset noise state to mean.\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Generate noise sample and update internal state.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(len(x))\n",
    "        self.state = x + dx\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31dc5a",
   "metadata": {},
   "source": [
    "## Section 7: DDPG Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706513cf",
   "metadata": {},
   "source": [
    "The DDPG Agent class combines actor and critic networks, noise, and replay buffer. It handles action selection, learning updates via sampled experiences, and smooth target network updates using a soft update mechanism.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f65d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"DDPG agent for environment interaction and learning.\"\"\"\n",
    "    def __init__(self, state_size, action_size, random_seed):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state_size (int): State dimension\n",
    "            action_size (int): Action dimension\n",
    "            random_seed (int): Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        # Actor networks\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        # Critic networks\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Exploration noise\n",
    "        self.noise = OUNoise(action_size, random_seed)\n",
    "\n",
    "        # Experience replay\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Generate action for a given state.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset noise process.\"\"\"\n",
    "        self.noise.reset()\n",
    "\n",
    "    def start_learn(self):\n",
    "        \"\"\"Trigger learning if buffer has sufficient samples.\"\"\"\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"\n",
    "        Update networks using a batch of experiences.\n",
    "        \n",
    "        Args:\n",
    "            experiences (tuple): Batch of (state, action, reward, next_state, done)\n",
    "            gamma (float): Discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Update critic\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), 1)\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # Update actor\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # Update target networks\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)\n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Update target network parameters smoothly.\n",
    "        \n",
    "        Args:\n",
    "            local_model (nn.Module): Source model\n",
    "            target_model (nn.Module): Target model\n",
    "            tau (float): Interpolation factor\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d0125",
   "metadata": {},
   "source": [
    "## Section 8: Training the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c635a",
   "metadata": {},
   "source": [
    "This section sets hyperparameters (e.g., buffer size, learning rates) and defines the DDPG training loop. The agent interacts with the environment, learns from experiences, and tracks scores until achieving a goal (average score ≥ 30). Results are plotted for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ced8af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BUFFER_SIZE = int(1e6)  # Replay buffer capacity\n",
    "BATCH_SIZE = 1024       # Minibatch size for learning\n",
    "GAMMA = 0.99            # Discount factor for future rewards\n",
    "TAU = 1e-3              # Soft update interpolation parameter\n",
    "LR_ACTOR = 1e-3         # Actor network learning rate\n",
    "LR_CRITIC = 1e-3        # Critic network learning rate\n",
    "WEIGHT_DECAY = 0        # L2 weight decay for critic optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d544d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent\n",
    "random_seed = 0\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a67df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDPG training function\n",
    "def ddpg(n_episodes=2000, max_t=1000, print_every=10, learn_every=20, num_learn=10, goal_score=30):\n",
    "    \"\"\"\n",
    "    Train DDPG agent in the Reacher environment.\n",
    "    \n",
    "    Args:\n",
    "        n_episodes (int): Maximum number of episodes\n",
    "        max_t (int): Maximum timesteps per episode\n",
    "        print_every (int): Interval for printing progress\n",
    "        learn_every (int): Interval for learning updates\n",
    "        num_learn (int): Number of learning updates per cycle\n",
    "        goal_score (float): Target average score to solve environment\n",
    "    \n",
    "    Returns:\n",
    "        list: Scores per episode\n",
    "    \"\"\"\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "\n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        episode_scores = np.zeros(num_agents)\n",
    "        start_time = time.time()\n",
    "\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states, add_noise=True)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done)\n",
    "\n",
    "            states = next_states\n",
    "            episode_scores += rewards\n",
    "\n",
    "            if t % learn_every == 0:\n",
    "                for _ in range(num_learn):\n",
    "                    agent.start_learn()\n",
    "\n",
    "            if any(dones):\n",
    "                break\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        mean_score = np.mean(episode_scores)\n",
    "        scores_deque.append(mean_score)\n",
    "        scores.append(mean_score)\n",
    "        avg_score = np.mean(scores_deque)\n",
    "\n",
    "        print(f'\\rEpisode {i_episode}\\tAvg Score: {avg_score:.2f}\\tMean: {mean_score:.2f}\\t'\n",
    "              f'Min: {np.min(episode_scores):.2f}\\tMax: {np.max(episode_scores):.2f}\\tTime: {duration:.2f}s')\n",
    "\n",
    "        if i_episode % print_every == 0:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            print(f'\\rEpisode {i_episode}\\tAvg Score: {avg_score:.2f}\\tTime: {duration:.2f}s')\n",
    "\n",
    "        if avg_score >= goal_score and i_episode >= 100:\n",
    "            print(f'\\nEnvironment solved in {i_episode} episodes!\\tAverage Score: {avg_score:.2f}')\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44719d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAvg Score: 0.27\tMean: 0.27\tMin: 0.00\tMax: 0.85\tTime: 232.06s\n",
      "Episode 2\tAvg Score: 0.30\tMean: 0.32\tMin: 0.00\tMax: 1.02\tTime: 245.50s\n",
      "Episode 3\tAvg Score: 0.36\tMean: 0.49\tMin: 0.00\tMax: 1.21\tTime: 246.40s\n",
      "Episode 4\tAvg Score: 0.42\tMean: 0.61\tMin: 0.00\tMax: 1.27\tTime: 244.79s\n",
      "Episode 5\tAvg Score: 0.40\tMean: 0.30\tMin: 0.00\tMax: 0.68\tTime: 244.00s\n",
      "Episode 6\tAvg Score: 0.42\tMean: 0.51\tMin: 0.00\tMax: 1.91\tTime: 244.61s\n",
      "Episode 7\tAvg Score: 0.47\tMean: 0.77\tMin: 0.18\tMax: 2.49\tTime: 243.50s\n",
      "Episode 8\tAvg Score: 0.57\tMean: 1.25\tMin: 0.07\tMax: 4.33\tTime: 240.28s\n",
      "Episode 9\tAvg Score: 0.65\tMean: 1.28\tMin: 0.00\tMax: 2.95\tTime: 232.20s\n",
      "Episode 10\tAvg Score: 0.75\tMean: 1.66\tMin: 0.00\tMax: 2.89\tTime: 224.18s\n",
      "Episode 10\tAvg Score: 0.75\tTime: 224.18s\n",
      "Episode 11\tAvg Score: 0.86\tMean: 2.00\tMin: 0.64\tMax: 4.29\tTime: 226.58s\n",
      "Episode 12\tAvg Score: 0.99\tMean: 2.38\tMin: 0.00\tMax: 4.56\tTime: 229.79s\n",
      "Episode 13\tAvg Score: 1.10\tMean: 2.50\tMin: 0.16\tMax: 5.50\tTime: 228.72s\n",
      "Episode 14\tAvg Score: 1.36\tMean: 4.62\tMin: 1.36\tMax: 10.10\tTime: 229.50s\n",
      "Episode 15\tAvg Score: 1.54\tMean: 4.12\tMin: 1.55\tMax: 8.69\tTime: 234.21s\n",
      "Episode 16\tAvg Score: 1.77\tMean: 5.29\tMin: 1.72\tMax: 10.30\tTime: 232.01s\n",
      "Episode 17\tAvg Score: 2.09\tMean: 7.05\tMin: 1.57\tMax: 14.22\tTime: 239.78s\n",
      "Episode 18\tAvg Score: 2.43\tMean: 8.23\tMin: 3.16\tMax: 14.91\tTime: 242.10s\n",
      "Episode 19\tAvg Score: 2.91\tMean: 11.66\tMin: 0.23\tMax: 20.29\tTime: 241.60s\n",
      "Episode 20\tAvg Score: 3.28\tMean: 10.20\tMin: 3.84\tMax: 23.92\tTime: 243.09s\n",
      "Episode 20\tAvg Score: 3.28\tTime: 243.09s\n",
      "Episode 21\tAvg Score: 3.85\tMean: 15.30\tMin: 2.81\tMax: 38.41\tTime: 242.79s\n",
      "Episode 22\tAvg Score: 4.49\tMean: 17.97\tMin: 8.53\tMax: 29.12\tTime: 245.38s\n",
      "Episode 23\tAvg Score: 5.17\tMean: 20.05\tMin: 11.90\tMax: 39.08\tTime: 247.00s\n",
      "Episode 24\tAvg Score: 5.87\tMean: 22.09\tMin: 12.58\tMax: 28.91\tTime: 252.79s\n",
      "Episode 25\tAvg Score: 6.43\tMean: 19.79\tMin: 9.17\tMax: 26.16\tTime: 251.89s\n",
      "Episode 26\tAvg Score: 7.18\tMean: 25.87\tMin: 18.83\tMax: 33.39\tTime: 253.30s\n",
      "Episode 27\tAvg Score: 7.99\tMean: 29.10\tMin: 18.96\tMax: 39.65\tTime: 250.58s\n",
      "Episode 28\tAvg Score: 8.67\tMean: 27.16\tMin: 16.63\tMax: 38.22\tTime: 254.79s\n",
      "Episode 29\tAvg Score: 9.42\tMean: 30.38\tMin: 21.21\tMax: 35.38\tTime: 250.99s\n",
      "Episode 30\tAvg Score: 10.10\tMean: 29.84\tMin: 22.20\tMax: 36.83\tTime: 249.90s\n",
      "Episode 30\tAvg Score: 10.10\tTime: 249.90s\n",
      "Episode 31\tAvg Score: 10.82\tMean: 32.36\tMin: 25.57\tMax: 39.17\tTime: 253.82s\n",
      "Episode 32\tAvg Score: 11.53\tMean: 33.39\tMin: 23.61\tMax: 39.40\tTime: 250.80s\n",
      "Episode 33\tAvg Score: 12.19\tMean: 33.45\tMin: 26.85\tMax: 38.97\tTime: 251.49s\n",
      "Episode 34\tAvg Score: 12.83\tMean: 33.85\tMin: 24.92\tMax: 39.18\tTime: 251.72s\n",
      "Episode 35\tAvg Score: 13.47\tMean: 35.23\tMin: 27.91\tMax: 39.45\tTime: 253.19s\n",
      "Episode 36\tAvg Score: 14.10\tMean: 36.14\tMin: 29.59\tMax: 38.74\tTime: 253.69s\n",
      "Episode 37\tAvg Score: 14.70\tMean: 36.49\tMin: 29.77\tMax: 38.97\tTime: 254.08s\n",
      "Episode 38\tAvg Score: 15.31\tMean: 37.84\tMin: 34.49\tMax: 39.64\tTime: 254.60s\n",
      "Episode 39\tAvg Score: 15.90\tMean: 38.33\tMin: 36.93\tMax: 39.55\tTime: 257.49s\n",
      "Episode 40\tAvg Score: 16.45\tMean: 38.01\tMin: 34.46\tMax: 39.57\tTime: 257.79s\n",
      "Episode 40\tAvg Score: 16.45\tTime: 257.79s\n",
      "Episode 41\tAvg Score: 16.97\tMean: 37.62\tMin: 31.08\tMax: 39.59\tTime: 264.38s\n",
      "Episode 42\tAvg Score: 17.47\tMean: 38.14\tMin: 35.49\tMax: 39.56\tTime: 260.38s\n",
      "Episode 43\tAvg Score: 17.95\tMean: 37.78\tMin: 36.62\tMax: 38.83\tTime: 267.19s\n",
      "Episode 44\tAvg Score: 18.42\tMean: 38.54\tMin: 37.59\tMax: 39.46\tTime: 266.90s\n",
      "Episode 45\tAvg Score: 18.86\tMean: 38.59\tMin: 37.32\tMax: 39.47\tTime: 272.41s\n",
      "Episode 46\tAvg Score: 19.28\tMean: 38.08\tMin: 35.94\tMax: 39.46\tTime: 274.77s\n",
      "Episode 47\tAvg Score: 19.70\tMean: 38.94\tMin: 37.88\tMax: 39.52\tTime: 276.10s\n",
      "Episode 48\tAvg Score: 20.10\tMean: 38.83\tMin: 36.43\tMax: 39.60\tTime: 282.19s\n",
      "Episode 49\tAvg Score: 20.48\tMean: 38.75\tMin: 35.73\tMax: 39.53\tTime: 285.39s\n",
      "Episode 50\tAvg Score: 20.85\tMean: 38.84\tMin: 37.45\tMax: 39.57\tTime: 293.69s\n",
      "Episode 50\tAvg Score: 20.85\tTime: 293.69s\n",
      "Episode 51\tAvg Score: 21.20\tMean: 38.73\tMin: 37.65\tMax: 39.35\tTime: 295.39s\n",
      "Episode 52\tAvg Score: 21.54\tMean: 39.01\tMin: 38.06\tMax: 39.62\tTime: 292.38s\n",
      "Episode 53\tAvg Score: 21.86\tMean: 38.66\tMin: 36.88\tMax: 39.56\tTime: 295.18s\n",
      "Episode 54\tAvg Score: 22.18\tMean: 39.13\tMin: 37.70\tMax: 39.61\tTime: 294.81s\n",
      "Episode 55\tAvg Score: 22.49\tMean: 39.22\tMin: 37.99\tMax: 39.62\tTime: 296.40s\n",
      "Episode 56\tAvg Score: 22.78\tMean: 38.68\tMin: 36.74\tMax: 39.59\tTime: 302.30s\n",
      "Episode 57\tAvg Score: 23.07\tMean: 39.14\tMin: 38.37\tMax: 39.56\tTime: 300.33s\n",
      "Episode 58\tAvg Score: 23.34\tMean: 38.62\tMin: 36.08\tMax: 39.40\tTime: 295.22s\n",
      "Episode 59\tAvg Score: 23.60\tMean: 39.02\tMin: 37.72\tMax: 39.48\tTime: 298.01s\n",
      "Episode 60\tAvg Score: 23.86\tMean: 39.14\tMin: 38.48\tMax: 39.58\tTime: 301.99s\n",
      "Episode 60\tAvg Score: 23.86\tTime: 301.99s\n",
      "Episode 61\tAvg Score: 24.11\tMean: 39.12\tMin: 37.45\tMax: 39.62\tTime: 300.19s\n",
      "Episode 62\tAvg Score: 24.35\tMean: 38.97\tMin: 37.94\tMax: 39.60\tTime: 301.48s\n",
      "Episode 63\tAvg Score: 24.58\tMean: 38.79\tMin: 37.53\tMax: 39.61\tTime: 303.21s\n",
      "Episode 64\tAvg Score: 24.80\tMean: 38.63\tMin: 36.76\tMax: 39.64\tTime: 301.89s\n",
      "Episode 65\tAvg Score: 25.02\tMean: 39.02\tMin: 37.38\tMax: 39.60\tTime: 303.11s\n",
      "Episode 66\tAvg Score: 25.22\tMean: 38.59\tMin: 37.84\tMax: 39.59\tTime: 306.38s\n",
      "Episode 67\tAvg Score: 25.43\tMean: 39.05\tMin: 37.46\tMax: 39.53\tTime: 310.49s\n",
      "Episode 68\tAvg Score: 25.63\tMean: 38.76\tMin: 37.73\tMax: 39.48\tTime: 319.99s\n",
      "Episode 69\tAvg Score: 25.82\tMean: 38.80\tMin: 37.18\tMax: 39.49\tTime: 320.68s\n",
      "Episode 70\tAvg Score: 26.01\tMean: 39.10\tMin: 38.03\tMax: 39.62\tTime: 329.39s\n",
      "Episode 70\tAvg Score: 26.01\tTime: 329.39s\n",
      "Episode 71\tAvg Score: 26.19\tMean: 38.96\tMin: 38.13\tMax: 39.59\tTime: 313.49s\n",
      "Episode 72\tAvg Score: 26.36\tMean: 38.68\tMin: 36.85\tMax: 39.63\tTime: 320.80s\n",
      "Episode 73\tAvg Score: 26.53\tMean: 38.41\tMin: 36.62\tMax: 39.39\tTime: 311.00s\n",
      "Episode 74\tAvg Score: 26.70\tMean: 39.41\tMin: 38.53\tMax: 39.62\tTime: 313.97s\n",
      "Episode 75\tAvg Score: 26.86\tMean: 38.70\tMin: 34.95\tMax: 39.63\tTime: 314.70s\n",
      "Episode 76\tAvg Score: 27.02\tMean: 39.05\tMin: 37.60\tMax: 39.61\tTime: 318.28s\n",
      "Episode 77\tAvg Score: 27.18\tMean: 38.84\tMin: 37.01\tMax: 39.57\tTime: 315.80s\n",
      "Episode 78\tAvg Score: 27.32\tMean: 38.69\tMin: 37.08\tMax: 39.53\tTime: 310.18s\n",
      "Episode 79\tAvg Score: 27.47\tMean: 39.14\tMin: 37.28\tMax: 39.62\tTime: 315.51s\n",
      "Episode 80\tAvg Score: 27.62\tMean: 38.87\tMin: 37.98\tMax: 39.62\tTime: 317.69s\n",
      "Episode 80\tAvg Score: 27.62\tTime: 317.69s\n",
      "Episode 81\tAvg Score: 27.76\tMean: 39.00\tMin: 37.75\tMax: 39.64\tTime: 312.38s\n",
      "Episode 82\tAvg Score: 27.89\tMean: 39.03\tMin: 38.21\tMax: 39.66\tTime: 317.00s\n",
      "Episode 83\tAvg Score: 28.02\tMean: 38.30\tMin: 36.59\tMax: 39.26\tTime: 313.78s\n",
      "Episode 84\tAvg Score: 28.15\tMean: 38.76\tMin: 37.18\tMax: 39.59\tTime: 343.29s\n",
      "Episode 85\tAvg Score: 28.27\tMean: 38.37\tMin: 37.20\tMax: 39.65\tTime: 352.89s\n",
      "Episode 86\tAvg Score: 28.39\tMean: 39.27\tMin: 38.25\tMax: 39.54\tTime: 340.89s\n",
      "Episode 87\tAvg Score: 28.52\tMean: 38.89\tMin: 38.08\tMax: 39.67\tTime: 341.01s\n",
      "Episode 88\tAvg Score: 28.64\tMean: 39.29\tMin: 37.58\tMax: 39.66\tTime: 335.76s\n",
      "Episode 89\tAvg Score: 28.75\tMean: 38.86\tMin: 38.24\tMax: 39.43\tTime: 310.60s\n",
      "Episode 90\tAvg Score: 28.86\tMean: 38.61\tMin: 36.55\tMax: 39.58\tTime: 309.78s\n",
      "Episode 90\tAvg Score: 28.86\tTime: 309.78s\n",
      "Episode 91\tAvg Score: 28.96\tMean: 37.77\tMin: 35.85\tMax: 39.50\tTime: 311.80s\n",
      "Episode 92\tAvg Score: 29.06\tMean: 38.05\tMin: 37.06\tMax: 39.52\tTime: 315.09s\n",
      "Episode 93\tAvg Score: 29.16\tMean: 38.51\tMin: 37.36\tMax: 39.47\tTime: 311.41s\n",
      "Episode 94\tAvg Score: 29.25\tMean: 38.00\tMin: 36.29\tMax: 39.52\tTime: 309.82s\n",
      "Episode 95\tAvg Score: 29.36\tMean: 38.97\tMin: 37.44\tMax: 39.61\tTime: 309.78s\n",
      "Episode 96\tAvg Score: 29.45\tMean: 38.47\tMin: 37.17\tMax: 39.42\tTime: 314.69s\n",
      "Episode 97\tAvg Score: 29.54\tMean: 38.18\tMin: 35.90\tMax: 39.51\tTime: 311.49s\n",
      "Episode 98\tAvg Score: 29.63\tMean: 37.93\tMin: 35.89\tMax: 39.08\tTime: 314.60s\n",
      "Episode 99\tAvg Score: 29.72\tMean: 38.42\tMin: 36.90\tMax: 39.33\tTime: 314.18s\n",
      "Episode 100\tAvg Score: 29.81\tMean: 38.67\tMin: 37.36\tMax: 39.56\tTime: 313.01s\n",
      "Episode 100\tAvg Score: 29.81\tTime: 313.01s\n",
      "Episode 101\tAvg Score: 30.19\tMean: 38.99\tMin: 37.89\tMax: 39.62\tTime: 313.48s\n",
      "\n",
      "Environment solved in 101 episodes!\tAverage Score: 30.19\n"
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ccdb596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "plt.plot(np.arange(1, len(scores) + 1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.title('DDPG Rewards per Episode')\n",
    "plt.savefig('ddpg_rewards_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5023f",
   "metadata": {},
   "source": [
    "## Section 9: Environment Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34b69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "#env.close()\n",
    "#cleanup_zombie_processes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7d6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
